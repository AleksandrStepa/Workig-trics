{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!!! Здесь описана очень старая версия бустинга. Текущая реализация для [мультибида](https://bitbucket.org/playgendary-dev/gap-runner/src/master/) и для [дефолтов](https://bitbucket.org/playgendary-dev/geo-defaults/src/master/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В схеме прогнозирования LTV для закупки трафика есть два этапа:\n",
    "\n",
    "- бустинг для прогнозирования монетизации ранних дней: для рекламы RPI7, для инапов RPI7, для подписок конверсия с 0 по 6 день;\n",
    "- полученные из бустинга прогнозы умножаются на соответствующие коэффициенты, чтобы получить прогноз LTV.\n",
    "\n",
    "На основании прогноза LTV и желаемой маржинальности выставляются биды (цена, за которую мы готовы купить пользователя).\n",
    "\n",
    "<a href=\"https://playgendary.atlassian.net/wiki/spaces/analytics/pages/57770079\">Описание биддинга</a>\n",
    "\n",
    "<a href=\"https://playgendary.atlassian.net/wiki/spaces/analytics/pages/55574630\">Биды для стран по умолчанию и мультибиддинг</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Выгрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import pandas_gbq\n",
    "import pydata_google_auth\n",
    "import logging\n",
    "\n",
    "SCOPES = [\n",
    "    'https://www.googleapis.com/auth/cloud-platform'\n",
    "]\n",
    "\n",
    "credentials = pydata_google_auth.get_user_credentials(\n",
    "    SCOPES,\n",
    "    auth_local_webserver=True,\n",
    ")\n",
    "\n",
    "logger = logging.getLogger('pandas_gbq')\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logger.addHandler(logging.StreamHandler())\n",
    "\n",
    "def execute(sql):\n",
    "    res = pandas_gbq.read_gbq(\n",
    "        sql,\n",
    "        project_id='playgendary-bi',\n",
    "        credentials=credentials,\n",
    "    )\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Минимальный разрез, на который мы выставляем бид - тайтл + страна + паблишер. Также добавим дополнительные фичи: название игры (общее для обеих платформ), платформа и версия приложения. Количество инсталлов используем в качестве весов. Не забываем про три разных таргета (ad RPI7, inapp RPI7 и subs conv6). Исходя из этого выгружаем данные для обучения (train) и теста (test)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Небольшие пояснения по запросу:\n",
    "- except_camp - исключаем оптимизационные кампании, так как их метрики обычно выше и для них биды выставляются отдельно\n",
    "- в запросе препроцессим названия паблишеров (siteId)\n",
    "- исключаем из источников органику и тестовые"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_day = 7\n",
    "subs_day = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''\n",
    "  WITH\n",
    "  except_camp AS (\n",
    "  SELECT\n",
    "    DISTINCT campaignName AS campaignName\n",
    "  FROM\n",
    "    `playgendary-bi.aggregated_data.daily_stat`\n",
    "  WHERE\n",
    "    date = \"{date}\"\n",
    "    AND ((mediaSource = \"unityads_int\"\n",
    "        AND (REGEXP_CONTAINS(LOWER(campaignName), \"7dreten\")\n",
    "          OR REGEXP_CONTAINS(LOWER(campaignName), \"roas\")))\n",
    "      OR (mediaSource = \"googleadwords_int\"\n",
    "        AND REGEXP_CONTAINS(LOWER(campaignName), \"action\"))\n",
    "      OR (mediaSource = \"Facebook Ads\"\n",
    "        AND (REGEXP_CONTAINS(LOWER(campaignName), \"_vo_\")\n",
    "          OR REGEXP_CONTAINS(LOWER(campaignName), \"_aeo_\"))))),\n",
    "  installs_t AS (\n",
    "  SELECT\n",
    "    LOWER(apps.app_name) AS appName,\n",
    "    LOWER(inst.appId) AS appId,\n",
    "    LOWER(inst.mediaSource) AS mediaSource,\n",
    "    LOWER(CONCAT(versions.app_version, '-', versions.appId)) AS appVersion,\n",
    "    CASE\n",
    "      WHEN inst.mediaSource = \"ironsource_int\" THEN LOWER(REGEXP_EXTRACT(inst.siteId, r\"[a-z\\.]*_|^(\\d+)_?\\w*\"))\n",
    "      WHEN inst.mediaSource = \"tapjoy_int\" THEN LOWER(REGEXP_EXTRACT(inst.siteId, r\".+_(\\w*)\"))\n",
    "      WHEN inst.mediaSource = \"vungle_int\" THEN LOWER(REGEXP_EXTRACT(inst.siteId, r\"^([^_]+)\"))\n",
    "      WHEN inst.mediaSource = \"googleadwords_int\" THEN LOWER(\n",
    "    IF\n",
    "      (inst.siteId = \"null\" OR inst.siteId is null,\n",
    "        \"GDN\",\n",
    "        inst.siteId))\n",
    "      WHEN inst.mediaSource IN (\"liftoff_int\", \"Apple Search Ads\") THEN LOWER(inst.mediaSource)\n",
    "      WHEN inst.mediaSource IN (\"Facebook Ads\",\n",
    "      \"snapchat_int\") THEN LOWER(adsetId)\n",
    "    ELSE\n",
    "    LOWER(inst.siteId)\n",
    "  END\n",
    "    AS siteId,\n",
    "    LOWER(inst.platform) AS platform,\n",
    "    LOWER(inst.countryCode) AS countryCode,\n",
    "    date AS installDate,\n",
    "    SUM(installs) AS installs\n",
    "  FROM\n",
    "    `playgendary-bi.aggregated_data.daily_stat` inst\n",
    "  INNER JOIN\n",
    "    `marketing-analytics-235713.auxiliary.apps_dictionary` AS apps\n",
    "  ON\n",
    "    apps.app_id = inst.appId\n",
    "  INNER JOIN\n",
    "    `marketing-analytics-235713.auxiliary.app_versions` AS versions\n",
    "  ON\n",
    "    versions.appId = inst.appId\n",
    "    AND versions.day = inst.date\n",
    "  WHERE\n",
    "    date = \"{date}\"\n",
    "    AND LOWER(inst.mediaSource) NOT IN ('organic', 'appsflyer_test', 'appsflyer_sdk_test_int')\n",
    "    AND inst.campaignName NOT IN (\n",
    "    SELECT\n",
    "      campaignName\n",
    "    FROM\n",
    "      except_camp)\n",
    "  GROUP BY\n",
    "    appName,\n",
    "    appId,\n",
    "    appVersion,\n",
    "    mediaSource,\n",
    "    siteId,\n",
    "    platform,\n",
    "    countryCode,\n",
    "    installDate),\n",
    "  subs AS (\n",
    "  SELECT\n",
    "    LOWER(appId) AS appId,\n",
    "    LOWER(mediaSource) AS mediaSource,\n",
    "    CASE\n",
    "      WHEN mediaSource = \"ironsource_int\" THEN LOWER(REGEXP_EXTRACT(siteId, r\"[a-z\\.]*_|^(\\d+)_?\\w*\"))\n",
    "      WHEN mediaSource = \"tapjoy_int\" THEN LOWER(REGEXP_EXTRACT(siteId, r\".+_(\\w*)\"))\n",
    "      WHEN mediaSource = \"vungle_int\" THEN LOWER(REGEXP_EXTRACT(siteId, r\"^([^_]+)\"))\n",
    "      WHEN mediaSource = \"googleadwords_int\" THEN LOWER(\n",
    "    IF\n",
    "      (siteId = \"null\" OR siteId is null,\n",
    "        \"GDN\",\n",
    "        siteId))\n",
    "      WHEN mediaSource IN (\"liftoff_int\", \"Apple Search Ads\") THEN LOWER(mediaSource)\n",
    "      WHEN mediaSource IN (\"Facebook Ads\",\n",
    "      \"snapchat_int\") THEN LOWER(adsetId)\n",
    "    ELSE\n",
    "    LOWER(siteId)\n",
    "  END\n",
    "    AS siteId,\n",
    "    LOWER(countryCode) AS countryCode,\n",
    "    installDate AS installDate,\n",
    "    SUM(eventCount) AS subs_conv\n",
    "  FROM\n",
    "    `playgendary-bi.aggregated_data.daily_inapp_revenue`\n",
    "  WHERE\n",
    "    installDate = '{date}'\n",
    "    AND eventDate BETWEEN installDate\n",
    "    AND DATE_ADD(installDate, INTERVAL {subs_day} DAY)\n",
    "    AND eventName NOT LIKE '%trial%'\n",
    "    AND eventName LIKE '%subscription_server%'\n",
    "    AND revenue IS NOT NULL\n",
    "    AND revenue != 0.0\n",
    "    AND LOWER(mediaSource) NOT IN ('organic', 'appsflyer_test', 'appsflyer_sdk_test_int')\n",
    "    AND campaignName NOT IN (\n",
    "    SELECT\n",
    "      campaignName\n",
    "    FROM\n",
    "      except_camp)\n",
    "  GROUP BY\n",
    "    appId,\n",
    "    mediaSource,\n",
    "    siteId,\n",
    "    countryCode,\n",
    "    installDate ),\n",
    "  ads AS (\n",
    "  SELECT\n",
    "    LOWER(agg.appId) AS appId,\n",
    "    LOWER(agg.mediaSource) AS mediaSource,\n",
    "    CASE\n",
    "      WHEN agg.mediaSource = \"ironsource_int\" THEN LOWER(REGEXP_EXTRACT(agg.siteId, r\"[a-z\\.]*_|^(\\d+)_?\\w*\"))\n",
    "      WHEN agg.mediaSource = \"tapjoy_int\" THEN LOWER(REGEXP_EXTRACT(agg.siteId, r\".+_(\\w*)\"))\n",
    "      WHEN agg.mediaSource = \"vungle_int\" THEN LOWER(REGEXP_EXTRACT(agg.siteId, r\"^([^_]+)\"))\n",
    "      WHEN agg.mediaSource = \"googleadwords_int\" THEN LOWER(\n",
    "    IF\n",
    "      (agg.siteId = \"null\",\n",
    "        \"GDN\",\n",
    "        agg.siteId))\n",
    "      WHEN agg.mediaSource IN (\"liftoff_int\", \"Apple Search Ads\") THEN LOWER(agg.mediaSource)\n",
    "      WHEN agg.mediaSource IN (\"Facebook Ads\",\n",
    "      \"snapchat_int\") THEN LOWER(adsetId)\n",
    "    ELSE\n",
    "    LOWER(agg.siteId)\n",
    "  END\n",
    "    AS siteId,\n",
    "    LOWER(agg.platform) AS platform,\n",
    "    LOWER(agg.countryCode) AS countryCode,\n",
    "    agg.installDate AS installDate,\n",
    "    SUM(\n",
    "    IF\n",
    "      (cohortDay <= {target_day},\n",
    "        adRevenue,\n",
    "        0)) AS ad_revenue,\n",
    "    SUM(\n",
    "    IF\n",
    "      (cohortDay <= {target_day},\n",
    "        inappRevenue,\n",
    "        0)) AS inapp_revenue\n",
    "  FROM\n",
    "        `playgendary-bi.aggregated_data.aggregated_cohort_revenue` AS agg\n",
    "  WHERE\n",
    "    agg.installDate = '{date}'\n",
    "    AND LOWER(agg.mediaSource) NOT IN ('organic', 'appsflyer_test', 'appsflyer_sdk_test_int')\n",
    "    AND agg.campaignName NOT IN (\n",
    "    SELECT\n",
    "      campaignName\n",
    "    FROM\n",
    "      except_camp)\n",
    "  GROUP BY\n",
    "    appId,\n",
    "    mediaSource,\n",
    "    installDate,\n",
    "    siteId,\n",
    "    platform,\n",
    "    countryCode )\n",
    "SELECT\n",
    "  inst.appName,\n",
    "  inst.appId,\n",
    "  inst.appVersion,\n",
    "  inst.mediaSource,\n",
    "  inst.siteId,\n",
    "  inst.platform,\n",
    "  inst.countryCode,\n",
    "  inst.installDate,\n",
    "  IFNULL(ad_revenue,\n",
    "    0) AS ad_revenue,\n",
    "  IFNULL(inapp_revenue,\n",
    "    0) AS purch_revenue,\n",
    "  IFNULL(subs_conv,\n",
    "    0) AS subs_conv,\n",
    "  installs\n",
    "FROM\n",
    "  installs_t AS inst\n",
    "LEFT JOIN\n",
    "  ads\n",
    "ON\n",
    "  ads.installDate = inst.installDate\n",
    "  AND ads.appId = inst.appId\n",
    "  AND ads.mediaSource = inst.mediaSource\n",
    "  AND ads.siteId = inst.siteId\n",
    "  AND ads.platform = inst.platform\n",
    "  AND ads.countryCode = inst.countryCode\n",
    "LEFT JOIN\n",
    "  subs\n",
    "ON\n",
    "  subs.installDate = inst.installDate\n",
    "  AND subs.appId = inst.appId\n",
    "  AND subs.mediaSource = inst.mediaSource\n",
    "  AND subs.siteId = inst.siteId\n",
    "  AND subs.countryCode = inst.countryCode\n",
    "WHERE\n",
    "  installs > 0\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выбираем даты для train и test. В данный момент для обучения используется 7 дней истории. Для теста также возьмем 7 дней. Чтобы приблизить ситуацию к боевой, не забываем, что между последней датой из train и первой из test должно быть 7+3 дней (7 - для накопления дней факта и 3 из-за задержки в данных)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dates = pd.date_range('2019-11-15', '2019-11-21').strftime('%Y-%m-%d').tolist()\n",
    "test_dates = pd.date_range('2019-12-01', '2019-12-07').strftime('%Y-%m-%d').tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Requesting query... \n",
      "Query running...\n",
      "Job ID: c6268871-d110-4333-ab83-6b98473b30de\n",
      "  Elapsed 6.66 s. Waiting...\n",
      "  Elapsed 8.78 s. Waiting...\n",
      "  Elapsed 10.64 s. Waiting...\n",
      "Query done.\n",
      "Processed: 209.6 MB Billed: 210.0 MB\n",
      "Standard price: $0.00 USD\n",
      "\n",
      "Got 285086 rows.\n",
      "\n",
      "Total time taken 47.93 s.\n",
      "Finished at 2019-12-17 15:29:09.\n",
      "Requesting query... \n",
      "Query running...\n",
      "Job ID: 4a02646e-2296-4d67-9255-f529f5a7a6c2\n",
      "  Elapsed 6.22 s. Waiting...\n",
      "  Elapsed 7.29 s. Waiting...\n",
      "  Elapsed 9.38 s. Waiting...\n",
      "  Elapsed 11.39 s. Waiting...\n",
      "Query done.\n",
      "Processed: 249.8 MB Billed: 250.0 MB\n",
      "Standard price: $0.00 USD\n",
      "\n",
      "Got 336801 rows.\n",
      "\n",
      "Total time taken 55.65 s.\n",
      "Finished at 2019-12-17 15:30:05.\n",
      "Requesting query... \n",
      "Query running...\n",
      "Job ID: c9197dcf-8d8c-4d85-9a57-35b9cc88d3f3\n",
      "  Elapsed 7.79 s. Waiting...\n",
      "  Elapsed 9.33 s. Waiting...\n",
      "  Elapsed 11.36 s. Waiting...\n",
      "Query done.\n",
      "Processed: 246.6 MB Billed: 247.0 MB\n",
      "Standard price: $0.00 USD\n",
      "\n",
      "Got 328326 rows.\n",
      "\n",
      "Total time taken 53.95 s.\n",
      "Finished at 2019-12-17 15:31:00.\n",
      "Requesting query... \n",
      "Query running...\n",
      "Job ID: 5b790807-890b-4374-8e56-f496d05845f0\n",
      "  Elapsed 6.39 s. Waiting...\n",
      "  Elapsed 8.11 s. Waiting...\n",
      "Query done.\n",
      "Processed: 174.0 MB Billed: 175.0 MB\n",
      "Standard price: $0.00 USD\n",
      "\n",
      "Got 237905 rows.\n",
      "\n",
      "Total time taken 39.62 s.\n",
      "Finished at 2019-12-17 15:31:40.\n",
      "Requesting query... \n",
      "Query running...\n",
      "Job ID: 3583d1c8-2fdb-4153-9c4c-d728332b0e0c\n",
      "  Elapsed 6.01 s. Waiting...\n",
      "  Elapsed 8.51 s. Waiting...\n",
      "Query done.\n",
      "Processed: 162.9 MB Billed: 163.0 MB\n",
      "Standard price: $0.00 USD\n",
      "\n",
      "Got 226301 rows.\n",
      "\n",
      "Total time taken 40.06 s.\n",
      "Finished at 2019-12-17 15:32:20.\n",
      "Requesting query... \n",
      "Query running...\n",
      "Job ID: 582c9e03-53a4-4358-890c-eb48c7ec817c\n",
      "  Elapsed 6.07 s. Waiting...\n",
      "  Elapsed 7.86 s. Waiting...\n",
      "Query done.\n",
      "Processed: 161.3 MB Billed: 162.0 MB\n",
      "Standard price: $0.00 USD\n",
      "\n",
      "Got 227968 rows.\n",
      "\n",
      "Total time taken 38.43 s.\n",
      "Finished at 2019-12-17 15:32:59.\n",
      "Requesting query... \n",
      "Query running...\n",
      "Job ID: 76c77678-0091-4345-8e70-e4835f363328\n",
      "  Elapsed 6.22 s. Waiting...\n",
      "Query done.\n",
      "Processed: 160.2 MB Billed: 161.0 MB\n",
      "Standard price: $0.00 USD\n",
      "\n",
      "Got 232728 rows.\n",
      "\n",
      "Total time taken 38.2 s.\n",
      "Finished at 2019-12-17 15:33:38.\n"
     ]
    }
   ],
   "source": [
    "for date in train_dates:\n",
    "    df = execute(query.format(date=date, target_day=target_day, subs_day=subs_day))\n",
    "    df.to_parquet('train/'+date+'.pq', engine='pyarrow', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Requesting query... \n",
      "Query running...\n",
      "Job ID: a11594a3-4ac3-476c-be36-0841b6a46185\n",
      "  Elapsed 7.78 s. Waiting...\n",
      "Query done.\n",
      "Processed: 193.7 MB Billed: 194.0 MB\n",
      "Standard price: $0.00 USD\n",
      "\n",
      "Got 310045 rows.\n",
      "\n",
      "Total time taken 48.61 s.\n",
      "Finished at 2019-12-17 15:34:45.\n",
      "Requesting query... \n",
      "Query running...\n",
      "Job ID: 825f5007-0119-4a37-b278-320b23f3baee\n",
      "  Elapsed 6.23 s. Waiting...\n",
      "Query done.\n",
      "Processed: 146.6 MB Billed: 147.0 MB\n",
      "Standard price: $0.00 USD\n",
      "\n",
      "Got 238771 rows.\n",
      "\n",
      "Total time taken 37.84 s.\n",
      "Finished at 2019-12-17 15:35:24.\n",
      "Requesting query... \n",
      "Query running...\n",
      "Job ID: 24fc2fc9-6f55-4d53-a29e-bf233097f7f1\n",
      "Query done.\n",
      "Processed: 139.5 MB Billed: 140.0 MB\n",
      "Standard price: $0.00 USD\n",
      "\n",
      "Got 238299 rows.\n",
      "\n",
      "Total time taken 39.09 s.\n",
      "Finished at 2019-12-17 15:36:03.\n",
      "Requesting query... \n",
      "Query running...\n",
      "Job ID: 0ba77d90-0866-4379-ba61-d324f92f4359\n",
      "  Elapsed 7.77 s. Waiting...\n",
      "Query done.\n",
      "Processed: 138.3 MB Billed: 139.0 MB\n",
      "Standard price: $0.00 USD\n",
      "\n",
      "Got 243478 rows.\n",
      "\n",
      "Total time taken 41.52 s.\n",
      "Finished at 2019-12-17 15:36:45.\n",
      "Requesting query... \n",
      "Query running...\n",
      "Job ID: 4dabae0d-675f-417d-b06e-4afc2ae66693\n",
      "  Elapsed 7.02 s. Waiting...\n",
      "Query done.\n",
      "Processed: 135.3 MB Billed: 136.0 MB\n",
      "Standard price: $0.00 USD\n",
      "\n",
      "Got 245813 rows.\n",
      "\n",
      "Total time taken 41.29 s.\n",
      "Finished at 2019-12-17 15:37:27.\n",
      "Requesting query... \n",
      "Query running...\n",
      "Job ID: 77e834af-ad17-4ffc-8ce4-748a519076ca\n",
      "  Elapsed 8.24 s. Waiting...\n",
      "  Elapsed 10.92 s. Waiting...\n",
      "  Elapsed 12.1 s. Waiting...\n",
      "Query done.\n",
      "Processed: 145.8 MB Billed: 146.0 MB\n",
      "Standard price: $0.00 USD\n",
      "\n",
      "Got 272871 rows.\n",
      "\n",
      "Total time taken 49.35 s.\n",
      "Finished at 2019-12-17 15:38:17.\n",
      "Requesting query... \n",
      "Query running...\n",
      "Job ID: 609e98d1-8015-46e2-a83b-51b58a388e4a\n",
      "  Elapsed 7.32 s. Waiting...\n",
      "  Elapsed 8.97 s. Waiting...\n",
      "Query done.\n",
      "Processed: 168.9 MB Billed: 169.0 MB\n",
      "Standard price: $0.00 USD\n",
      "\n",
      "Got 324389 rows.\n",
      "\n",
      "Total time taken 53.25 s.\n",
      "Finished at 2019-12-17 15:39:10.\n"
     ]
    }
   ],
   "source": [
    "for date in test_dates:\n",
    "    df = execute(query.format(date=date, target_day=target_day, subs_day=subs_day))\n",
    "    df.to_parquet('test/'+date+'.pq', engine='pyarrow', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_parquet('train/')\n",
    "test = pd.read_parquet('test/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>appName</th>\n",
       "      <th>appId</th>\n",
       "      <th>appVersion</th>\n",
       "      <th>mediaSource</th>\n",
       "      <th>siteId</th>\n",
       "      <th>platform</th>\n",
       "      <th>countryCode</th>\n",
       "      <th>installDate</th>\n",
       "      <th>ad_revenue</th>\n",
       "      <th>purch_revenue</th>\n",
       "      <th>subs_conv</th>\n",
       "      <th>installs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>615206</th>\n",
       "      <td>polysphere</td>\n",
       "      <td>com.playgendary.polyspherecoolgame</td>\n",
       "      <td>1.4.6-com.playgendary.polyspherecoolgame</td>\n",
       "      <td>unityads_int</td>\n",
       "      <td>1624308</td>\n",
       "      <td>android</td>\n",
       "      <td>ke</td>\n",
       "      <td>2019-11-16</td>\n",
       "      <td>0.02201</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1797897</th>\n",
       "      <td>tomb of the mask: color</td>\n",
       "      <td>com.playgendary.tombpaint</td>\n",
       "      <td>1.0.3-com.playgendary.tombpaint</td>\n",
       "      <td>ironsource_int</td>\n",
       "      <td>262361</td>\n",
       "      <td>android</td>\n",
       "      <td>hn</td>\n",
       "      <td>2019-11-21</td>\n",
       "      <td>0.01340</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>960717</th>\n",
       "      <td>tomb of the mask</td>\n",
       "      <td>id1057889290</td>\n",
       "      <td>1.7.2-id1057889290</td>\n",
       "      <td>ironsource_int</td>\n",
       "      <td>237563</td>\n",
       "      <td>ios</td>\n",
       "      <td>es</td>\n",
       "      <td>2019-11-18</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1233735</th>\n",
       "      <td>polysphere</td>\n",
       "      <td>id1440756080</td>\n",
       "      <td>1.4.6-id1440756080</td>\n",
       "      <td>applovin_int</td>\n",
       "      <td>b613f60ec8caf47e18b0e2dd26d537a4</td>\n",
       "      <td>ios</td>\n",
       "      <td>us</td>\n",
       "      <td>2019-11-19</td>\n",
       "      <td>2.46159</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174883</th>\n",
       "      <td>tomb of the mask</td>\n",
       "      <td>com.playgendary.tom</td>\n",
       "      <td>1.4.1-com.playgendary.tom</td>\n",
       "      <td>unityads_int</td>\n",
       "      <td>3121203</td>\n",
       "      <td>android</td>\n",
       "      <td>in</td>\n",
       "      <td>2019-11-15</td>\n",
       "      <td>0.04828</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         appName                               appId  \\\n",
       "615206                polysphere  com.playgendary.polyspherecoolgame   \n",
       "1797897  tomb of the mask: color           com.playgendary.tombpaint   \n",
       "960717          tomb of the mask                        id1057889290   \n",
       "1233735               polysphere                        id1440756080   \n",
       "174883          tomb of the mask                 com.playgendary.tom   \n",
       "\n",
       "                                       appVersion     mediaSource  \\\n",
       "615206   1.4.6-com.playgendary.polyspherecoolgame    unityads_int   \n",
       "1797897           1.0.3-com.playgendary.tombpaint  ironsource_int   \n",
       "960717                         1.7.2-id1057889290  ironsource_int   \n",
       "1233735                        1.4.6-id1440756080    applovin_int   \n",
       "174883                  1.4.1-com.playgendary.tom    unityads_int   \n",
       "\n",
       "                                   siteId platform countryCode installDate  \\\n",
       "615206                            1624308  android          ke  2019-11-16   \n",
       "1797897                            262361  android          hn  2019-11-21   \n",
       "960717                             237563      ios          es  2019-11-18   \n",
       "1233735  b613f60ec8caf47e18b0e2dd26d537a4      ios          us  2019-11-19   \n",
       "174883                            3121203  android          in  2019-11-15   \n",
       "\n",
       "         ad_revenue  purch_revenue  subs_conv  installs  \n",
       "615206      0.02201            0.0          0         1  \n",
       "1797897     0.01340            0.0          0         1  \n",
       "960717      0.00002            0.0          0         1  \n",
       "1233735     2.46159            0.0          0         5  \n",
       "174883      0.04828            0.0          0         1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Подготовка test и label encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    'appName',\n",
    "    'appId',\n",
    "    'appVersion',\n",
    "    'mediaSource',\n",
    "    'siteId',\n",
    "    'platform',\n",
    "    'countryCode'\n",
    "]\n",
    "\n",
    "weight_col = 'installs'\n",
    "target_cols = ['ad_revenue', 'purch_revenue', 'subs_conv']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сгруппируем данные, так как мы не используем информацию по installDate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_grp = train.groupby(features, as_index=False)[[weight_col] + target_cols].sum()\n",
    "test_grp = test.groupby(features, as_index=False)[[weight_col] + target_cols].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для теста используем последнюю версию приложения c достаточным количеством инсталлов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_APPVERSION_INSTALLS = 5000\n",
    "\n",
    "def select_appVersion(df):\n",
    "    if df.shape[0] == 1:\n",
    "        return df['appVersion'].values[0]\n",
    "        \n",
    "    df['enough'] = (df['installs'] >= MIN_APPVERSION_INSTALLS)\n",
    "    if df['enough'].sum() > 1:\n",
    "        return df.loc[df['enough']]['appVersion'].max()\n",
    "    else:\n",
    "        return df.nlargest(1, 'installs')['appVersion'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_grp.drop(['appVersion'], axis=1, inplace=True)\n",
    "tmp = train_grp.groupby(['appId', 'appVersion'])['installs'].sum().reset_index()\n",
    "versions = tmp.groupby('appId').apply(select_appVersion)\\\n",
    "              .to_frame(name='appVersion').reset_index()\n",
    "test_grp = test_grp.merge(versions, on='appId', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отбираем только тех паблишеров, которые были в обучении с достаточным количеством инсталлов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_INSTALLS = 100\n",
    "\n",
    "test_filtered = test_grp.merge(train_grp, on=features, suffixes=(\"\", \"_train\"))\n",
    "test_filtered = test_filtered.loc[test_filtered[weight_col + \"_train\"] >= MIN_INSTALLS].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее используем label encoder https://bitbucket.org/playgendary-dev/label-encoder/src/master/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from labenc import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder().fit(train_grp[features])\n",
    "encoder.save('encoder.pkl')\n",
    "\n",
    "train_encoded = encoder.transform(train_grp)\n",
    "test_encoded = encoder.transform(test_filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Подбор гиперпараметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/lightgbm/__init__.py:46: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_8.3.3) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "from hyperopt import hp, tpe, space_eval, Trials\n",
    "from hyperopt.fmin import fmin\n",
    "from hyperopt.pyll.base import scope\n",
    "@scope.define\n",
    "def to_int(x):\n",
    "    return int(max(1, x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Помимо гиперпараметров самого бустинга, добавим еще weight_power - степень, в которую возводим количество инсталлов (веса), чтобы уменьшить влияние крупных когорт. В качестве оптимизационной метрики для рекламного дохода используем MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col = 'ad_revenue'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "space = {\n",
    "    'learning_rate': hp.uniform('learning_rate', 0.01, 0.4),\n",
    "    'num_leaves': hp.choice('num_leaves', [2**5 - 1, 2**6 - 1, 2**7 - 1]),\n",
    "    \n",
    "    'max_cat_threshold': scope.to_int(hp.quniform('max_cat_threshold', 2, 500, 15)),\n",
    "    'cat_l2': scope.to_int(hp.quniform('cat_l2', 1, 1000, 25)),\n",
    "    'cat_smooth': scope.to_int(hp.quniform('cat_smooth', 2, 1000, 25)),\n",
    "    \n",
    "    'bagging_fraction': hp.uniform('bagging_fraction', 0.4, 1.),\n",
    "    'bagging_freq': scope.to_int(hp.quniform('bagging_freq', 0, 3, 1)),\n",
    "    'feature_fraction': hp.uniform('feature_fraction', 0.4, 1.),\n",
    "    \n",
    "    'max_bin': hp.choice('max_bin', [2**7 - 1, 2**8 - 1, 2**9-1, 2**10-1]),\n",
    "    \n",
    "    'boosting': 'gbdt',\n",
    "    'reg_sqrt': False,\n",
    "    \n",
    "    'min_data_per_group': 1,\n",
    "    'min_data_in_leaf': 1,\n",
    "    'min_sum_hessian_in_leaf': hp.uniform('min_sum_hessian_in_leaf', 1e-4, 1),\n",
    "    \n",
    "    \n",
    "    \"weight_power\": hp.uniform('weight_power', 0.1, 1.), \n",
    "    \n",
    "    'verbose': 1,\n",
    "    'objective': 'mse',\n",
    "    'metric': 'mse',\n",
    "    'bagging_seed': 322,\n",
    "    'feature_fraction_seed': 322,\n",
    "    'first_metric_only': True,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux_params = {\n",
    "    'num_boost_round': 500,\n",
    "    'early_stopping_rounds': 5,\n",
    "    'verbose_eval': 50\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    \n",
    "    lgb_train = lgb.Dataset(\n",
    "        data=train_encoded[features],\n",
    "        label=train_encoded[target_col] / train_encoded[weight_col],\n",
    "        weight=train_encoded[weight_col] ** (params['weight_power']),\n",
    "        categorical_feature=features)\n",
    "    params.pop('weight_power')\n",
    "    \n",
    "    lgb_test = lgb.Dataset(\n",
    "        data=test_encoded[features],\n",
    "        label=test_encoded[target_col] / test_encoded[weight_col],\n",
    "        weight=test_encoded[weight_col],\n",
    "        categorical_feature=features)\n",
    "    \n",
    "    res = lgb.train(\n",
    "        params=params,\n",
    "        train_set=lgb_train,\n",
    "        valid_sets=lgb_test,\n",
    "        **aux_params)\n",
    "    \n",
    "    return res.best_score['valid_0']['l2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/10 [00:00<?, ?it/s, best loss: ?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/lightgbm/basic.py:1205: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds.\n",
      "  0%|          | 0/10 [00:00<?, ?it/s, best loss: ?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/lightgbm/basic.py:762: UserWarning: categorical_feature in param dict is overridden.\n",
      "  warnings.warn('categorical_feature in param dict is overridden.')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\tvalid_0's l2: 0.000406019                      \n",
      "Early stopping, best iteration is:                  \n",
      "[89]\tvalid_0's l2: 0.000341601\n",
      "Training until validation scores don't improve for 5 rounds.                     \n",
      "[50]\tvalid_0's l2: 0.000721573                                                   \n",
      "[100]\tvalid_0's l2: 0.000512274                                                  \n",
      "Early stopping, best iteration is:                                               \n",
      "[121]\tvalid_0's l2: 0.000480128\n",
      "Training until validation scores don't improve for 5 rounds.                     \n",
      "[50]\tvalid_0's l2: 0.000713697                                                   \n",
      "[100]\tvalid_0's l2: 0.000508399                                                  \n",
      "Early stopping, best iteration is:                                               \n",
      "[96]\tvalid_0's l2: 0.000504479\n",
      "Training until validation scores don't improve for 5 rounds.                     \n",
      "Early stopping, best iteration is:                                               \n",
      "[19]\tvalid_0's l2: 0.00112555\n",
      "Training until validation scores don't improve for 5 rounds.                     \n",
      "[50]\tvalid_0's l2: 0.000413517                                                   \n",
      "Early stopping, best iteration is:                                               \n",
      "[78]\tvalid_0's l2: 0.000371786\n",
      "Training until validation scores don't improve for 5 rounds.                     \n",
      "[50]\tvalid_0's l2: 0.000903988                                                   \n",
      "Early stopping, best iteration is:                                               \n",
      "[87]\tvalid_0's l2: 0.000701613\n",
      "Training until validation scores don't improve for 5 rounds.                     \n",
      "[50]\tvalid_0's l2: 0.000267916                                                   \n",
      "Early stopping, best iteration is:                                               \n",
      "[92]\tvalid_0's l2: 0.000220275\n",
      "Training until validation scores don't improve for 5 rounds.                     \n",
      "[50]\tvalid_0's l2: 0.000397549                                                  \n",
      "[100]\tvalid_0's l2: 0.000307102                                                 \n",
      "Early stopping, best iteration is:                                              \n",
      "[121]\tvalid_0's l2: 0.000291345\n",
      "Training until validation scores don't improve for 5 rounds.                    \n",
      "[50]\tvalid_0's l2: 0.00100004                                                   \n",
      "Early stopping, best iteration is:                                              \n",
      "[52]\tvalid_0's l2: 0.000987567\n",
      "Training until validation scores don't improve for 5 rounds.                    \n",
      "[50]\tvalid_0's l2: 0.000501652                                                  \n",
      "[100]\tvalid_0's l2: 0.000402955                                                 \n",
      "[150]\tvalid_0's l2: 0.000342577                                                 \n",
      "[200]\tvalid_0's l2: 0.000323591                                                 \n",
      "Early stopping, best iteration is:                                              \n",
      "[209]\tvalid_0's l2: 0.000319749\n",
      "100%|██████████| 10/10 [00:44<00:00,  5.50s/it, best loss: 0.0002202747986891532]\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=10,\n",
    "            trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bagging_fraction': 0.5792207964941026,\n",
       " 'bagging_freq': 1,\n",
       " 'bagging_seed': 322,\n",
       " 'boosting': 'gbdt',\n",
       " 'cat_l2': 900,\n",
       " 'cat_smooth': 100,\n",
       " 'feature_fraction': 0.5931811855652239,\n",
       " 'feature_fraction_seed': 322,\n",
       " 'first_metric_only': True,\n",
       " 'learning_rate': 0.12964016071429868,\n",
       " 'max_bin': 511,\n",
       " 'max_cat_threshold': 495,\n",
       " 'metric': 'mse',\n",
       " 'min_data_in_leaf': 1,\n",
       " 'min_data_per_group': 1,\n",
       " 'min_sum_hessian_in_leaf': 0.9074814514558993,\n",
       " 'num_leaves': 127,\n",
       " 'objective': 'mse',\n",
       " 'reg_sqrt': False,\n",
       " 'verbose': 1,\n",
       " 'weight_power': 0.8009176625701054}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params = space_eval(space, best)\n",
    "best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Повторяем процедуру для других таргетов. Для инапов используем MSE, для подписок - cross_entropy (xentropy в валидации)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds.\n",
      "[50]\tvalid_0's l2: 0.000267916\n",
      "Early stopping, best iteration is:\n",
      "[92]\tvalid_0's l2: 0.000220275\n"
     ]
    }
   ],
   "source": [
    "lgb_train = lgb.Dataset(\n",
    "    data=train_encoded[features],\n",
    "    label=train_encoded[target_col] / train_encoded[weight_col],\n",
    "    weight=train_encoded[weight_col] ** (best_params['weight_power']),\n",
    "    categorical_feature=features)\n",
    "\n",
    "lgb_test = lgb.Dataset(\n",
    "    data=test_encoded[features],\n",
    "    label=test_encoded[target_col] / test_encoded[weight_col],\n",
    "    weight=test_encoded[weight_col],\n",
    "    categorical_feature=features)\n",
    "\n",
    "res = lgb.train(\n",
    "    params=best_params,\n",
    "    train_set=lgb_train,\n",
    "    valid_sets=lgb_test,\n",
    "    **aux_params)\n",
    "\n",
    "test_encoded[f'{target_col}_pred'] = res.predict(test_encoded[features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Повторяем для других таргетов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Меряем ошибку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import  mean_squared_error, mean_absolute_error, median_absolute_error, r2_score\n",
    "\n",
    "def cross_entropy(y, p, w):\n",
    "    return np.sum((-y*np.log(p)-(1-y)*np.log(1-p))*w)/np.sum(w)\n",
    "\n",
    "def calc_metrics(preds, y, sample_weight, xentropy=False):\n",
    "    output = {\n",
    "        'weighted_cross_entropy': cross_entropy(y, preds, sample_weight) if xentropy else None,\n",
    "        'weighted_mean_squared_error': mean_squared_error(y, preds, sample_weight),\n",
    "        'weighted_mean_absolute_error': mean_absolute_error(y, preds, sample_weight),\n",
    "        'mean_squared_error': mean_squared_error(y, preds),\n",
    "        'mean_absolute_error': mean_absolute_error(y, preds),\n",
    "        'median_absolute_error': median_absolute_error(y, preds),\n",
    "        'weighted_r2_score': r2_score(y, preds, sample_weight),\n",
    "        'r2_score': r2_score(y, preds),\n",
    "\n",
    "        'target_test_mean': y.mean(),\n",
    "        'prediction_test_mean': preds.mean(),\n",
    "\n",
    "        'weighted_target_test_mean': np.average(y, weights=sample_weight),\n",
    "        'weighted_prediction_test_mean': np.average(preds, weights=sample_weight),\n",
    "    }\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'weighted_cross_entropy': None,\n",
       " 'weighted_mean_squared_error': 0.00022027479774115963,\n",
       " 'weighted_mean_absolute_error': 0.005472188882348486,\n",
       " 'mean_squared_error': 0.0018423297231395304,\n",
       " 'mean_absolute_error': 0.01603167190046626,\n",
       " 'median_absolute_error': 0.00453604301622737,\n",
       " 'weighted_r2_score': 0.9433237602636073,\n",
       " 'r2_score': 0.780700028234995,\n",
       " 'target_test_mean': 0.05042287309610533,\n",
       " 'prediction_test_mean': 0.05198970049395405,\n",
       " 'weighted_target_test_mean': 0.027948535274660295,\n",
       " 'weighted_prediction_test_mean': 0.02880063109541742}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_metrics(test_encoded[f'{target_col}_pred'], \n",
    "             test_encoded[target_col]/test_encoded[weight_col], \n",
    "             test_encoded[weight_col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Репозиторий https://bitbucket.org/playgendary-dev/gap-runner/src/master/\n",
    "\n",
    "Брифинг по бустингу https://drive.google.com/drive/folders/1KmqCF-x_4f7fDeDEgyImlTlpIsoXPFiv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
